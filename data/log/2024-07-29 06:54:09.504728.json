{"task": "relevancy", "last_date_published": "2020-01-18T00:00:00Z", "new_last_date_pulished": "2020-01-28T00:00:00Z", "articles": [{"id": "30a2c9b450475104184f57f73bb344b7", "title": "Gradient Surgery for Multi-Task Learning", "date_published": "2020-01-19T00:00:00Z", "relevancy": 7, "relevancy_justification": "The paper discusses challenges in multi-task learning, which is relevant to AI alignment research. It introduces a method called PCGrad that mitigates gradient interference in multi-task learning, which could potentially be useful for solving AI alignment problems. However, the paper does not directly address AI alignment, so the relevancy is not extremely high."}, {"id": "894271b0598a47c63a47d1833d6a38fa", "title": "The Incentives that Shape Behaviour", "date_published": "2020-01-20T00:00:00Z", "relevancy": 5, "relevancy_justification": "The research paper discusses the definition and graphical criteria for control incentives in structural causal models, which is directly relevant to my project on finding novel solutions to solve AI alignment problems. The paper also provides a comparison with the previous definitions of intervention incentives and observation incentives, which can help me understand the differences and potential improvements in the existing approaches."}, {"id": "d2386b5bab1151ae84700ec595a55c69", "title": "Explaining Data-Driven Decisions made by AI Systems: The Counterfactual Approach", "date_published": "2020-01-21T00:00:00Z", "relevancy": 7, "relevancy_justification": "The research paper discusses the challenges of explaining AI system decisions, which is directly relevant to AI alignment research. It introduces the concept of counterfactual explanations, which could be a novel approach to consider in AI alignment. However, it does not directly address the specific project of finding novel solutions to AI alignment, hence the score is not 10."}, {"id": "05f4d77d6506976cd221aca7938d68a1", "title": "Designing for the Long Tail of Machine Learning", "date_published": "2020-01-21T00:00:00Z", "relevancy": 7, "relevancy_justification": "The research paper discusses the design process of ML-based systems, which is relevant to AI alignment. It highlights the trade-offs between data gathering, model development, and human-centered design, and introduces the concept of the 'long tail' of machine learning, which could be relevant to long-term AI alignment considerations. However, it does not directly address AI alignment or value alignment, which is the primary focus of your project."}, {"id": "e3b91b56243224fbce42b0c510b39c68", "title": "Subjective Knowledge and Reasoning about Agents in Multi-Agent Systems", "date_published": "2020-01-22T00:00:00Z", "relevancy": 7, "relevancy_justification": "The research paper discusses extending epistemic logic to support reasoning about agency in multi-agent systems, which is relevant to AI alignment research. It introduces modal operators to express an agent's certainty about the presence of other agents and defines model transformation operators to update the system with new agents or remove existing ones. However, it does not directly address novel solutions to AI alignment problems, which is why the relevancy score is not 10."}, {"id": "535b6ebabb1b259665a9a1ec1be389b6", "title": "What's a Good Prediction? Challenges in evaluating an agent's knowledge", "date_published": "2020-01-23T00:00:00Z", "relevancy": 7, "relevancy_justification": "The paper discusses the use of predictive knowledge in AI, which is relevant to AI alignment research. It also touches on the challenges of evaluating predictions and deciding what to learn, which are important considerations for AI alignment. However, the paper is more focused on the technical aspects of predictive knowledge and evaluation methods, rather than the alignment aspects."}, {"id": "d164e84c2d47a8b98431e3b222dc7ed8", "title": "Scaling Laws for Neural Language Models", "date_published": "2020-01-23T00:00:00Z", "relevancy": 7, "relevancy_justification": "The research paper discusses scaling laws for neural language models, which is directly relevant to AI alignment research. The paper investigates how language modeling performance depends on various factors such as model size, dataset size, and compute budget, which are all relevant to finding novel solutions for AI alignment. Additionally, the paper provides empirical evidence and power-law relationships that could be useful for understanding and predicting the behavior of large language models, which is a key aspect of AI alignment research."}, {"id": "6311d79b1c153e4a7a4ff3fd932f3dea", "title": "Silly rules improve the capacity of agents to learn stable enforcement and compliance behaviors", "date_published": "2020-01-25T00:00:00Z", "relevancy": 7, "relevancy_justification": "The research paper explores the emergence and enforcement of norms in a multi-agent reinforcement learning environment, which is relevant to AI alignment research. However, it focuses on the legibility of norms and their impact on learning, rather than novel solutions to AI alignment problems. Therefore, it is not extremely relevant."}, {"id": "7add01516d3cbae17e16e80d51b46a07", "title": "Towards a Human-like Open-Domain Chatbot", "date_published": "2020-01-27T00:00:00Z", "relevancy": 7, "relevancy_justification": "The research paper discusses the development of an open-domain chatbot named Meena, which is trained on a large-scale dataset of social media conversations. The paper introduces a new evaluation metric called Sensibleness and Specificity Average (SSA) to measure the quality of chatbot responses. While the paper does not directly address AI alignment, the development of more human-like chatbots could potentially help in understanding and aligning human values and preferences. Additionally, the use of a large-scale dataset and an end-to-end neural network approach could inspire new methods for aligning AI systems with human values."}, {"id": "b26648e7d3c2e4a815769958b50d60fc", "title": "Towards Learning Multi-agent Negotiations via Self-Play", "date_published": "2020-01-28T00:00:00Z", "relevancy": 8, "relevancy_justification": "The research paper is directly relevant to your project on AI alignment, as it explores the use of reinforcement learning to learn robust and capable policies for multi-agent systems in complex environments. The paper also discusses the challenges of learning safe and robust sequential decisions in complex environments, which is a key challenge in AI alignment. Additionally, the paper introduces the concept of self-play, which could be a useful technique for increasing the complexity of the environment and learning better policies in your project."}]}